import json
import boto3
import os
import re
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional

def handler(event, context):
    print("=== EVENT RECEIVED ===")
    print(json.dumps(event))
    
    try:
        # CloudWatchã‚¢ãƒ©ãƒ¼ãƒ ã‹ã‚‰ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’å‡¦ç†
        if 'Records' in event:
            # SNSçµŒç”±ã§ã®ã‚¤ãƒ™ãƒ³ãƒˆ
            for record in event['Records']:
                if record['EventSource'] == 'aws:sns':
                    message = json.loads(record['Sns']['Message'])
                    process_alarm_event(message)
        else:
            # ç›´æ¥ã®CloudWatchã‚¢ãƒ©ãƒ¼ãƒ ã‚¤ãƒ™ãƒ³ãƒˆ
            process_alarm_event(event)
            
        return {
            "statusCode": 200,
            "body": json.dumps({
                "message": "Error notification processed successfully"
            })
        }
        
    except Exception as e:
        print(f"Error processing event: {str(e)}")
        return {
            "statusCode": 500,
            "body": json.dumps({
                "message": f"Error: {str(e)}"
            })
        }

def process_alarm_event(alarm_data: Dict[str, Any]):
    """CloudWatchã‚¢ãƒ©ãƒ¼ãƒ ã‚¤ãƒ™ãƒ³ãƒˆã‚’å‡¦ç†ï¼ˆå‹•çš„è¨­å®šå–å¾—ç‰ˆï¼‰"""
    
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å¿…è¦æœ€å°é™ã®è¨­å®šã®ã¿å–å¾—
    email_sns_topic_arn = os.environ.get('EMAIL_SNS_TOPIC_ARN')
    
    if not email_sns_topic_arn:
        raise ValueError("EMAIL_SNS_TOPIC_ARN environment variable not set")
    
    # SNSçµŒç”±ã®CloudWatchã‚¢ãƒ©ãƒ¼ãƒ ã‚¤ãƒ™ãƒ³ãƒˆã®æ§‹é€ ã«å¯¾å¿œ
    if 'AlarmName' in alarm_data:
        # SNSçµŒç”±ã®CloudWatchã‚¢ãƒ©ãƒ¼ãƒ å½¢å¼ï¼ˆæ¨™æº–å½¢å¼ï¼‰
        alarm_name = alarm_data.get('AlarmName', 'Unknown')
        alarm_description = alarm_data.get('AlarmDescription', '')
        new_state = alarm_data.get('NewStateValue', 'UNKNOWN')
        reason = alarm_data.get('NewStateReason', '')
        timestamp = alarm_data.get('StateChangeTime', datetime.now().isoformat())
    elif 'alarmData' in alarm_data:
        # ç›´æ¥å‘¼ã³å‡ºã—å½¢å¼ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ä¿æŒï¼‰
        alarm_info = alarm_data['alarmData']
        alarm_name = alarm_info.get('alarmName', 'Unknown')
        alarm_description = alarm_data.get('alarmDescription', '')
        state_info = alarm_info.get('state', {})
        new_state = state_info.get('value', 'UNKNOWN')
        reason = state_info.get('reason', '')
        timestamp = state_info.get('timestamp', datetime.now().isoformat())
    else:
        raise ValueError("Unknown alarm event format")
    
    print(f"Processing alarm: {alarm_name}, State: {new_state}")
    
    # ã‚¢ãƒ©ãƒ¼ãƒ çŠ¶æ…‹ãŒALARMã®å ´åˆã®ã¿å‡¦ç†
    if new_state == 'ALARM':
        try:
            # ã‚¢ãƒ©ãƒ¼ãƒ æƒ…å ±ã‹ã‚‰å‹•çš„ã«ãƒ­ã‚°ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±ã‚’å–å¾—
            log_group_info = get_log_group_info_from_alarm(alarm_name)
            
            log_group_name = log_group_info['log_group_name']
            filter_pattern = log_group_info['filter_pattern']
            display_name = log_group_info['display_name']
            description = log_group_info['description']
            
            print(f"Dynamic config - Log Group: {log_group_name}")
            print(f"Dynamic config - Filter Pattern: {filter_pattern}")
            print(f"Dynamic config - Display Name: {display_name}")
            
        except Exception as e:
            print(f"Error getting dynamic log group configuration: {e}")
            return
        
        print(f"Identified log group: {log_group_name}, filter: {filter_pattern}")
        
        # NewStateReasonã‹ã‚‰evaluatedDatapointsã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’æŠ½å‡º
        datapoint_timestamp = extract_datapoint_timestamp_from_reason(reason)
        print(f"Extracted datapoint timestamp: {datapoint_timestamp}")
        
        # æœ€è¿‘ã®ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’å–å¾—ï¼ˆæ”¹å–„ã•ã‚ŒãŸæ–¹æ³•ï¼‰
        if datapoint_timestamp:
            error_logs = get_logs_from_datapoint_period(log_group_name, filter_pattern, datapoint_timestamp)
            print(f"Retrieved {len(error_logs)} error logs using datapoint period method")
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®æ–¹æ³•
            error_logs = get_recent_error_logs(log_group_name, filter_pattern)
            print(f"Retrieved {len(error_logs)} error logs using fallback method")
        
        # ãƒ‡ãƒãƒƒã‚°: å–å¾—ã—ãŸãƒ­ã‚°ã®å†…å®¹ã‚’å‡ºåŠ›
        for i, log in enumerate(error_logs[:3]):
            print(f"Log {i+1}: {log.get('message', '')[:100]}...")
        
        # ãƒ¡ãƒ¼ãƒ«å†…å®¹ã‚’ç”Ÿæˆï¼ˆä»¶åã¨æœ¬æ–‡ï¼‰
        search_method = "datapoint_period" if datapoint_timestamp else "fallback"
        subject, body = generate_email_content(
            alarm_name, alarm_description, timestamp, reason, error_logs, 
            log_group_name, display_name, search_method
        )
        
        # ãƒ‡ãƒãƒƒã‚°: ãƒ¡ãƒ¼ãƒ«å†…å®¹ã‚’å‡ºåŠ›
        print(f"Email subject: {subject}")
        print(f"Email body preview: {body[:500]}...")
        
        # SNSçµŒç”±ã§ãƒ¡ãƒ¼ãƒ«é€ä¿¡
        send_notification(email_sns_topic_arn, subject, body)

def get_log_group_info_from_alarm(alarm_name: str) -> Dict[str, str]:
    """
    CloudWatch APIã‚’ä½¿ç”¨ã—ã¦ã‚¢ãƒ©ãƒ¼ãƒ ã«é–¢é€£ã™ã‚‹ãƒ­ã‚°ã‚°ãƒ«ãƒ¼ãƒ—ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å‹•çš„ã«å–å¾—
    """
    cloudwatch = boto3.client('cloudwatch')
    logs_client = boto3.client('logs')
    
    try:
        # 1. ã‚¢ãƒ©ãƒ¼ãƒ ã®è©³ç´°æƒ…å ±ã‚’å–å¾—
        response = cloudwatch.describe_alarms(AlarmNames=[alarm_name])
        
        if not response['MetricAlarms']:
            raise ValueError(f"Alarm not found: {alarm_name}")
        
        alarm = response['MetricAlarms'][0]
        metric_name = alarm['MetricName']
        namespace = alarm['Namespace']
        
        print(f"Alarm metric: {namespace}/{metric_name}")
        
        # 2. ã‚¢ãƒ©ãƒ¼ãƒ åã‹ã‚‰ç›´æ¥ãƒ­ã‚°ã‚°ãƒ«ãƒ¼ãƒ—åã‚’æ¨å®šï¼ˆæ–°ã—ã„å‘½åãƒ«ãƒ¼ãƒ«ï¼‰
        log_group_name = infer_log_group_name_from_alarm_name(alarm_name)
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ¡ãƒˆãƒªã‚¯ã‚¹æƒ…å ±ã‹ã‚‰ã‚‚æ¨å®šã‚’è©¦è¡Œ
        if not log_group_name:
            log_group_name = infer_log_group_name_from_metric(metric_name, namespace)
        
        # 3. ãƒ­ã‚°ã‚°ãƒ«ãƒ¼ãƒ—ã®å­˜åœ¨ç¢ºèª
        verify_log_group_exists(logs_client, log_group_name)
        
        # 4. ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‹ã‚‰ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å–å¾—
        filter_pattern = get_filter_pattern_from_log_group(logs_client, log_group_name, metric_name)
        
        # 5. è¡¨ç¤ºåã¨èª¬æ˜ã‚’ç”Ÿæˆ
        display_name = generate_display_name(log_group_name)
        description = generate_description(log_group_name, display_name)
        
        return {
            "log_group_name": log_group_name,
            "display_name": display_name,
            "filter_pattern": filter_pattern,
            "description": description
        }
        
    except Exception as e:
        print(f"Error getting log group info from alarm: {e}")
        raise

def infer_log_group_name_from_alarm_name(alarm_name: str) -> str:
    """
    ã‚¢ãƒ©ãƒ¼ãƒ åã‹ã‚‰ãƒ­ã‚°ã‚°ãƒ«ãƒ¼ãƒ—åã‚’ç›´æ¥æ¨å®š
    æ–°ã—ã„å‘½åãƒ«ãƒ¼ãƒ«: ã‚¢ãƒ©ãƒ¼ãƒ åã®æœ€å¾Œã®éƒ¨åˆ†ï¼ˆ-Errorã€-Warningç­‰ï¼‰ã‚’ã‚«ãƒƒãƒˆã—ã¦ãƒ­ã‚°ã‚°ãƒ«ãƒ¼ãƒ—åã¨ã™ã‚‹
    
    ä¾‹:
    - "LS-AWSLAB-EC2-MTA01-Messages-Error" â†’ "LS-AWSLAB-EC2-MTA01-Messages"
    - "LS-AWSLAB-EC2-MTA01-App-Warning" â†’ "LS-AWSLAB-EC2-MTA01-App"
    - "LS-AWSLAB-API-Gateway-App-Critical" â†’ "LS-AWSLAB-API-Gateway-App"
    """
    # ã‚¢ãƒ©ãƒ¼ãƒ åã‚’"-"ã§åˆ†å‰²
    parts = alarm_name.split("-")
    
    if len(parts) > 1:
        # æœ€å¾Œã®éƒ¨åˆ†ãŒã‚¢ãƒ©ãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«ï¼ˆErrorã€Warningã€Criticalç­‰ï¼‰ã¨æ€ã‚ã‚Œã‚‹å ´åˆã¯å‰Šé™¤
        last_part = parts[-1].lower()
        alert_levels = ["error", "warning", "critical", "info", "debug", "alarm", "alert"]
        
        if last_part in alert_levels:
            log_group_name = "-".join(parts[:-1])
        else:
            # æœ€å¾Œã®éƒ¨åˆ†ãŒã‚¢ãƒ©ãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«ã§ãªã„å ´åˆã¯ãã®ã¾ã¾ä½¿ç”¨
            log_group_name = alarm_name
    else:
        # "-"ãŒå«ã¾ã‚Œã¦ã„ãªã„å ´åˆã¯ãã®ã¾ã¾ä½¿ç”¨
        log_group_name = alarm_name
    
    print(f"Inferred log group name from alarm '{alarm_name}': {log_group_name}")
    return log_group_name

def infer_log_group_name_from_metric(metric_name: str, namespace: str) -> str:
    """
    ãƒ¡ãƒˆãƒªã‚¯ã‚¹åã¨åå‰ç©ºé–“ã‹ã‚‰ãƒ­ã‚°ã‚°ãƒ«ãƒ¼ãƒ—åã‚’æ¨å®šï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ä¿æŒï¼‰
    """
    if namespace == "LS-AWSLAB-ErrorMonitoring":
        # æ–°ã—ã„å‘½åè¦å‰‡: "EC2-MTA01-Messages-Error" â†’ "LS-AWSLAB-EC2-MTA01-Messages"
        log_group_suffix = metric_name.replace("-Error", "")
        log_group_name = f"LS-AWSLAB-{log_group_suffix}"
            
    elif namespace == "LS-AWSLAB-EC2-MTA01":
        # æ—¢å­˜ã®å‘½åè¦å‰‡ï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰
        if "messages" in metric_name.lower():
            log_group_name = "LS-AWSLAB-EC2-MTA01-Log-messages"
        elif "app" in metric_name.lower():
            log_group_name = "LS-AWSLAB-EC2-MTA01-Log-app"
        else:
            log_group_name = "LS-AWSLAB-EC2-MTA01-Log-messages"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    else:
        raise ValueError(f"Unknown namespace: {namespace}")
    
    return log_group_name

def verify_log_group_exists(logs_client, log_group_name: str):
    """
    ãƒ­ã‚°ã‚°ãƒ«ãƒ¼ãƒ—ã®å­˜åœ¨ç¢ºèª
    """
    try:
        response = logs_client.describe_log_groups(
            logGroupNamePrefix=log_group_name,
            limit=1
        )
        
        if not response['logGroups'] or response['logGroups'][0]['logGroupName'] != log_group_name:
            raise ValueError(f"Log group not found: {log_group_name}")
            
        print(f"Log group verified: {log_group_name}")
        
    except Exception as e:
        print(f"Error verifying log group: {e}")
        raise

def get_filter_pattern_from_log_group(logs_client, log_group_name: str, metric_name: str) -> str:
    """
    ãƒ­ã‚°ã‚°ãƒ«ãƒ¼ãƒ—ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‹ã‚‰å®Ÿéš›ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å–å¾—
    """
    try:
        # ãƒ­ã‚°ã‚°ãƒ«ãƒ¼ãƒ—ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’å–å¾—
        response = logs_client.describe_metric_filters(
            logGroupName=log_group_name
        )
        
        metric_filters = response.get('metricFilters', [])
        
        if not metric_filters:
            print(f"No metric filters found for log group: {log_group_name}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ­ã‚°ã‚°ãƒ«ãƒ¼ãƒ—åã‹ã‚‰æ¨å®š
            return infer_filter_pattern_from_log_group_name(log_group_name)
        
        # è¤‡æ•°ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãŒã‚ã‚‹å ´åˆã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹åã§ç‰¹å®š
        target_filter = None
        for filter_info in metric_filters:
            for transformation in filter_info.get('metricTransformations', []):
                if transformation.get('metricName') == metric_name:
                    target_filter = filter_info
                    break
            if target_filter:
                break
        
        if target_filter:
            filter_pattern = target_filter.get('filterPattern', '')
            print(f"Found filter pattern from metric filter: {filter_pattern}")
            return filter_pattern
        else:
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åãŒä¸€è‡´ã—ãªã„å ´åˆã€æœ€åˆã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’ä½¿ç”¨
            filter_pattern = metric_filters[0].get('filterPattern', '')
            print(f"Using first available filter pattern: {filter_pattern}")
            return filter_pattern
            
    except Exception as e:
        print(f"Error getting filter pattern from metric filters: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ­ã‚°ã‚°ãƒ«ãƒ¼ãƒ—åã‹ã‚‰æ¨å®š
        return infer_filter_pattern_from_log_group_name(log_group_name)

def infer_filter_pattern_from_log_group_name(log_group_name: str) -> str:
    """
    ãƒ­ã‚°ã‚°ãƒ«ãƒ¼ãƒ—åã‹ã‚‰ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¨å®šï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
    æ–°ã—ã„å‘½åãƒ«ãƒ¼ãƒ«å¯¾å¿œ
    """
    log_group_lower = log_group_name.lower()
    
    # æ–°ã—ã„å‘½åãƒ«ãƒ¼ãƒ«: ãƒ­ã‚°ã‚°ãƒ«ãƒ¼ãƒ—åã®æœ«å°¾ã§åˆ¤å®š
    if log_group_lower.endswith("-messages"):
        return "[error]"
    elif log_group_lower.endswith("-app"):
        return "ERROR"
    # å¾Œæ–¹äº’æ›æ€§: å¤ã„å‘½åè¦å‰‡
    elif "log-messages" in log_group_lower:
        return "[error]"
    elif "log-app" in log_group_lower:
        return "ERROR"
    else:
        return "ERROR"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

def generate_display_name(log_group_name: str) -> str:
    """
    ãƒ­ã‚°ã‚°ãƒ«ãƒ¼ãƒ—åã‹ã‚‰è¡¨ç¤ºåã‚’ç”Ÿæˆ
    æ–°ã—ã„å‘½åãƒ«ãƒ¼ãƒ«: ãƒ­ã‚°ã‚°ãƒ«ãƒ¼ãƒ—åã‹ã‚‰"LS-AWSLAB-"ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’å‰Šé™¤
    """
    # "LS-AWSLAB-EC2-MTA01-Messages" â†’ "EC2-MTA01-Messages"
    if log_group_name.startswith("LS-AWSLAB-"):
        display_name = log_group_name.replace("LS-AWSLAB-", "")
    else:
        display_name = log_group_name
    
    # å¾Œæ–¹äº’æ›æ€§: å¤ã„å‘½åè¦å‰‡ã«ã‚‚å¯¾å¿œ
    if display_name.endswith("-Log-messages"):
        display_name = display_name.replace("-Log-messages", "-Messages")
    elif display_name.endswith("-Log-app"):
        display_name = display_name.replace("-Log-app", "-App")
    
    return display_name

def generate_description(log_group_name: str, display_name: str) -> str:
    """
    ãƒ­ã‚°ã‚°ãƒ«ãƒ¼ãƒ—ã®èª¬æ˜ã‚’ç”Ÿæˆ
    æ–°ã—ã„å‘½åãƒ«ãƒ¼ãƒ«å¯¾å¿œ
    """
    log_group_lower = log_group_name.lower()
    
    # æ–°ã—ã„å‘½åãƒ«ãƒ¼ãƒ«: ãƒ­ã‚°ã‚°ãƒ«ãƒ¼ãƒ—åã®æœ«å°¾ã§åˆ¤å®š
    if log_group_lower.endswith("-messages"):
        log_type = "ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"
    elif log_group_lower.endswith("-app"):
        log_type = "ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"
    # å¾Œæ–¹äº’æ›æ€§: å¤ã„å‘½åè¦å‰‡
    elif "log-messages" in log_group_lower:
        log_type = "ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"
    elif "log-app" in log_group_lower:
        log_type = "ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"
    else:
        log_type = "ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"
    
    # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹/ã‚µãƒ¼ãƒ“ã‚¹åã‚’æŠ½å‡º
    if "EC2-MTA01" in display_name:
        instance_name = "EC2ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹(MTA01)"
    elif "API-Gateway" in display_name:
        instance_name = "API Gateway"
    elif "Lambda" in display_name:
        instance_name = "Lambdaé–¢æ•°"
    else:
        # æ±ç”¨çš„ãªæŠ½å‡º: æœ€åˆã®éƒ¨åˆ†ã‚’ä½¿ç”¨
        parts = display_name.split("-")
        if len(parts) >= 2:
            instance_name = f"{parts[0]}-{parts[1]}"
        else:
            instance_name = parts[0] if parts else display_name
    
    return f"{instance_name}ã®{log_type}ãƒ­ã‚°"

def extract_datapoint_timestamp_from_reason(state_reason: str) -> Optional[str]:
    """
    NewStateReasonã‹ã‚‰evaluatedDatapointsã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’æŠ½å‡º
    
    Args:
        state_reason: CloudWatchã‚¢ãƒ©ãƒ¼ãƒ ã®NewStateReason
        ä¾‹: "Threshold Crossed: 1 datapoint [2.0 (04/08/25 05:16:00)] was greater than..."
    
    Returns:
        str: ISOå½¢å¼ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ— ("2025-08-04T05:16:00.000Z") ã¾ãŸã¯ None
    """
    if not state_reason:
        return None
    
    try:
        # ãƒ‘ã‚¿ãƒ¼ãƒ³1: (YY/MM/DD HH:MM:SS) å½¢å¼
        pattern1 = r'\((\d{2}/\d{2}/\d{2} \d{2}:\d{2}:\d{2})\)'
        match1 = re.search(pattern1, state_reason)
        
        if match1:
            timestamp_str = match1.group(1)  # "05/08/25 04:05:00"
            print(f"Matched timestamp pattern: {timestamp_str}")
            
            # YY/MM/DDå½¢å¼ã‚’æ­£ã—ãè§£é‡ˆï¼ˆ25 = 2025å¹´ï¼‰
            # æ—¥ä»˜å½¢å¼: DD/MM/YY ãªã®ã§ã€å¹´ã¯æœ€å¾Œã®2æ¡
            parts = timestamp_str.split(' ')
            date_part = parts[0]  # "05/08/25"
            time_part = parts[1]  # "04:05:00"
            
            date_components = date_part.split('/')  # ["05", "08", "25"]
            year_part = date_components[2]  # "25"
            
            if int(year_part) <= 50:  # 00-50ã¯20xxå¹´ã€51-99ã¯19xxå¹´
                full_year = f"20{year_part}"
            else:
                full_year = f"19{year_part}"
            
            # æ­£ã—ã„å¹´ã‚’ä½¿ã£ã¦æ—¥ä»˜ã‚’æ§‹ç¯‰ (YYYY/MM/DD HH:MM:SS)
            corrected_timestamp = f"{full_year}/{date_components[1]}/{date_components[0]} {time_part}"
            print(f"Corrected timestamp: {corrected_timestamp}")
            dt = datetime.strptime(corrected_timestamp, "%Y/%m/%d %H:%M:%S")
            iso_timestamp = dt.strftime("%Y-%m-%dT%H:%M:%S.000Z")
            
            return iso_timestamp
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³2: ä»–ã®å½¢å¼ãŒã‚ã‚Œã°è¿½åŠ å¯èƒ½
        # pattern2 = r'...'
        
        print(f"No timestamp pattern matched in: {state_reason}")
        return None
        
    except Exception as e:
        print(f"Error extracting timestamp from state reason: {e}")
        return None

def get_logs_from_datapoint_period(log_group_name: str, filter_pattern: str, 
                                 datapoint_timestamp: str) -> List[Dict[str, Any]]:
    """
    evaluatedDatapointsã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’åŸºæº–ã«ã—ãŸãƒ­ã‚°å–å¾—
    
    Args:
        log_group_name: ãƒ­ã‚°ã‚°ãƒ«ãƒ¼ãƒ—å
        filter_pattern: ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³
        datapoint_timestamp: evaluatedDatapointsã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ— (ISOå½¢å¼)
    
    Returns:
        list: ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®ãƒªã‚¹ãƒˆ
    """
    logs_client = boto3.client('logs')
    
    try:
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
        start_time = datetime.fromisoformat(datapoint_timestamp.replace('Z', '+00:00'))
        
        # Periodã‚’å–å¾—ï¼ˆç¾åœ¨ã¯å›ºå®šå€¤ã€å°†æ¥çš„ã«ã¯ã‚¢ãƒ©ãƒ¼ãƒ è¨­å®šã‹ã‚‰å–å¾—å¯èƒ½ï¼‰
        # TODO: ã‚¢ãƒ©ãƒ¼ãƒ è¨­å®šã‹ã‚‰å‹•çš„ã«å–å¾—ã™ã‚‹æ–¹æ³•ã‚’æ¤œè¨
        period_seconds = 300  # 5åˆ†é–“ï¼ˆç¾åœ¨ã®è¨­å®šï¼‰
        
        end_time = start_time + timedelta(seconds=period_seconds)
        
        print(f"Searching logs from {start_time} to {end_time} (period: {period_seconds}s)")
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ­£è¦åŒ–
        if filter_pattern == "[error]":
            search_pattern = "error"
        else:
            search_pattern = filter_pattern
        
        response = logs_client.filter_log_events(
            logGroupName=log_group_name,
            startTime=int(start_time.timestamp() * 1000),
            endTime=int(end_time.timestamp() * 1000),
            filterPattern=search_pattern,
            limit=20  # å°‘ã—å¤šã‚ã«å–å¾—
        )
        
        events = response.get('events', [])
        
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—é †ã«ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
        events.sort(key=lambda x: x['timestamp'], reverse=True)
        
        print(f"Found {len(events)} logs in datapoint period")
        return events[:10]  # æœ€å¤§10ä»¶ã‚’è¿”ã™
        
    except Exception as e:
        print(f"Error fetching logs from datapoint period: {e}")
        return []

def get_recent_error_logs(log_group_name: str, filter_pattern: str, hours_back: int = 1) -> List[Dict[str, Any]]:
    """æœ€è¿‘ã®ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’å–å¾—"""
    
    logs_client = boto3.client('logs')
    
    # æ¤œç´¢æœŸé–“ã‚’è¨­å®šï¼ˆéå»1æ™‚é–“ï¼‰
    end_time = datetime.now()
    start_time = end_time - timedelta(hours=hours_back)
    
    try:
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ­£è¦åŒ–ï¼ˆCloudWatch Logsã®å½¢å¼ã«åˆã‚ã›ã‚‹ï¼‰
        if filter_pattern == "[error]":
            # æ—¢å­˜ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ãã®ã¾ã¾ä½¿ç”¨
            search_pattern = "error"
        else:
            # æ–°ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ãã®ã¾ã¾ä½¿ç”¨
            search_pattern = filter_pattern
        
        response = logs_client.filter_log_events(
            logGroupName=log_group_name,
            startTime=int(start_time.timestamp() * 1000),
            endTime=int(end_time.timestamp() * 1000),
            filterPattern=search_pattern,
            limit=10  # æœ€å¤§10ä»¶ã®ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’å–å¾—
        )
        
        return response.get('events', [])
        
    except Exception as e:
        print(f"Error fetching logs from {log_group_name}: {str(e)}")
        return []

def generate_email_content(alarm_name: str, alarm_description: str, 
                         timestamp: str, reason: str, 
                         error_logs: List[Dict[str, Any]], 
                         log_group_name: str, display_name: str,
                         search_method: str = "unknown") -> tuple:
    """ãƒ¡ãƒ¼ãƒ«ã®ä»¶åã¨æœ¬æ–‡ã‚’ç”Ÿæˆ"""
    
    # ä»¶å
    subject = f"ğŸš¨ AWS Alert: {display_name} - ã‚¨ãƒ©ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ"
    
    # ãƒ­ã‚°ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸèª¬æ˜ã‚’ç”Ÿæˆ
    log_type_descriptions = {
        "EC2-MTA01-Messages": "EC2ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹(awslab-mta01)ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ­ã‚°",
        "EC2-MTA01-App": "EC2ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹(awslab-mta01)ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚°", 
        "APIGW-mtkhs-App01": "API Gateway(mtkhs-App01)",
        "Lambda-mtkhs-App01": "Lambdaé–¢æ•°(mtkhs-App01)"
    }
    
    log_description = log_type_descriptions.get(display_name, f"{display_name}ã®ãƒ­ã‚°")
    
    # æœ¬æ–‡
    body = f"""
AWS CloudWatchã‚¢ãƒ©ãƒ¼ãƒ ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚

ã€ã‚¢ãƒ©ãƒ¼ãƒ æƒ…å ±ã€‘
ãƒ»ã‚¢ãƒ©ãƒ¼ãƒ å: {alarm_name}
ãƒ»å¯¾è±¡ãƒ­ã‚°: {log_description}
ãƒ»ãƒ­ã‚°ã‚°ãƒ«ãƒ¼ãƒ—: {log_group_name}
ãƒ»èª¬æ˜: {alarm_description}
ãƒ»ç™ºç”Ÿæ™‚åˆ»: {timestamp}
ãƒ»ç†ç”±: {reason}

ã€æ¤œå‡ºã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã€‘
"""
    
    if error_logs:
        # æ¤œç´¢æ–¹æ³•ã«å¿œã˜ãŸèª¬æ˜ã‚’ç”Ÿæˆ
        if search_method == "datapoint_period":
            body += f"ã‚¢ãƒ©ãƒ¼ãƒ ç™ºç”Ÿã®åŸå› ã¨ãªã£ãŸãƒ¡ãƒˆãƒªã‚¯ã‚¹æœŸé–“ï¼ˆ5åˆ†é–“ï¼‰ã§ {len(error_logs)} ä»¶ã®ã‚¨ãƒ©ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ:\n\n"
        else:
            body += f"éå»1æ™‚é–“ã§ {len(error_logs)} ä»¶ã®ã‚¨ãƒ©ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ:\n\n"
        
        for i, log_event in enumerate(error_logs[:5], 1):  # æœ€å¤§5ä»¶è¡¨ç¤º
            log_time = datetime.fromtimestamp(log_event['timestamp'] / 1000)
            message = log_event['message']
            
            # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ•´å½¢ï¼ˆé•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚Šè©°ã‚ï¼‰
            if len(message) > 300:
                message = message[:300] + "..."
            
            body += f"{i}. {log_time.strftime('%Y-%m-%d %H:%M:%S')}\n"
            body += f"   {message}\n\n"
            
        if len(error_logs) > 5:
            body += f"... ä»– {len(error_logs) - 5} ä»¶ã®ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãŒã‚ã‚Šã¾ã™\n\n"
    else:
        body += "è©³ç´°ãªã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n\n"
    
    # å¯¾å¿œæ–¹æ³•ãƒ–ãƒ­ãƒƒã‚¯ã‚’å‰Šé™¤ï¼ˆä¸è¦ãªãŸã‚ï¼‰
    action_guide = ""
    
    # URLã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ­ã‚°ã‚°ãƒ«ãƒ¼ãƒ—åã‚’ç”Ÿæˆ
    import urllib.parse
    encoded_log_group = urllib.parse.quote(log_group_name, safe='')
    
    body += f"""
ã€ãƒ­ã‚°ç¢ºèªURLã€‘
https://ap-northeast-1.console.aws.amazon.com/cloudwatch/home?region=ap-northeast-1#logsV2:log-groups/log-group/{encoded_log_group}

ã“ã®ãƒ¡ãƒ¼ãƒ«ã¯è‡ªå‹•é€ä¿¡ã•ã‚Œã¦ã„ã¾ã™ã€‚
"""
    
    return subject, body

def send_notification(sns_topic_arn: str, subject: str, body: str):
    """SNSçµŒç”±ã§ãƒ¡ãƒ¼ãƒ«é€šçŸ¥ã‚’é€ä¿¡"""
    
    sns_client = boto3.client('sns')
    
    try:
        # ç›´æ¥SESã‚’ä½¿ç”¨ã—ã¦unsubscribeãƒªãƒ³ã‚¯ã‚’å›é¿
        # ã¾ãšã¯SNSã§é€ä¿¡ï¼ˆæ—¢å­˜ã®ä»•çµ„ã¿ã‚’ç¶­æŒï¼‰
        response = sns_client.publish(
            TopicArn=sns_topic_arn,
            Subject=subject,
            Message=body
        )
        
        print(f"Notification sent successfully. MessageId: {response['MessageId']}")
        
    except Exception as e:
        print(f"Error sending notification: {str(e)}")
        raise

